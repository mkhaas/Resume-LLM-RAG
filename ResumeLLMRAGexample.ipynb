{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkhaas/Resume-LLM-RAG/blob/main/ResumeLLMRAGexample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d647f70",
      "metadata": {
        "id": "0d647f70"
      },
      "source": [
        "# Vectorstores and Embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing required libraries"
      ],
      "metadata": {
        "id": "xSe3GDwGzWs_"
      },
      "id": "xSe3GDwGzWs_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8d2266-4a35-4904-ae9d-c89790c5ae61",
      "metadata": {
        "height": 180,
        "tags": [],
        "id": "7f8d2266-4a35-4904-ae9d-c89790c5ae61"
      },
      "outputs": [],
      "source": [
        "# Installing required libraries\n",
        "!pip install openai\n",
        "!pip install cohere\n",
        "!pip install langchain\n",
        "!pip install chromadb\n",
        "!pip install tiktoken\n",
        "!pip install langchain[sentence-transformers]\n",
        "!pip install sentence-transformers\n",
        "!pip install pypdf\n",
        "!pip install huggingface_hub\n",
        "!pip install langchain[HuggingFace]\n",
        "\n",
        "# Importing necessary modules\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "# Importing specific components from langchain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2437469e",
      "metadata": {
        "height": 248,
        "tags": [],
        "id": "2437469e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Loading PDF documents using PyPDFLoader\n",
        "loaders = [\n",
        "    PyPDFLoader(\"./Langchain-Tester-Resume.pdf\")\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb44bf0d",
      "metadata": {
        "height": 129,
        "tags": [],
        "id": "eb44bf0d"
      },
      "outputs": [],
      "source": [
        "# Splitting documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 150,\n",
        "    chunk_overlap = 15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b71e46cc",
      "metadata": {
        "height": 31,
        "tags": [],
        "id": "b71e46cc"
      },
      "outputs": [],
      "source": [
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e061f22d",
      "metadata": {
        "height": 31,
        "tags": [],
        "id": "e061f22d",
        "outputId": "405fe256-6767-45d1-a02e-e4a9b99e1c4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "848e26fd",
      "metadata": {
        "id": "848e26fd"
      },
      "source": [
        "## Embeddings\n",
        "\n",
        "Using Open Source HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing HuggingFaceEmbeddings with a specific model\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "5o-aXwebOImp"
      },
      "id": "5o-aXwebOImp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4fc7b24f",
      "metadata": {
        "id": "4fc7b24f"
      },
      "source": [
        "## Vectorstores\n",
        "In memory Chromadb.  Initializing an in-memory Chromadb with document embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93960ac5",
      "metadata": {
        "height": 31,
        "tags": [],
        "id": "93960ac5"
      },
      "outputs": [],
      "source": [
        "persist_directory = 'docs/chroma/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a195e72a",
      "metadata": {
        "height": 44,
        "tags": [],
        "id": "a195e72a"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./docs/chroma  # remove old database files if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690efd0a",
      "metadata": {
        "height": 99,
        "tags": [],
        "id": "690efd0a"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f777480c",
      "metadata": {
        "height": 31,
        "tags": [],
        "id": "f777480c",
        "outputId": "b729963d-589d-4f28-897a-ae98a64a6478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ],
      "source": [
        "print(vectordb._collection.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efca7589",
      "metadata": {
        "id": "efca7589"
      },
      "source": [
        "### Similarity Search using a question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e20837d",
      "metadata": {
        "height": 31,
        "tags": [],
        "id": "3e20837d"
      },
      "outputs": [],
      "source": [
        "question = \"What is Langchain Tester's email?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9bde572",
      "metadata": {
        "height": 31,
        "tags": [],
        "id": "f9bde572"
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41388af1",
      "metadata": {
        "height": 31,
        "tags": [],
        "id": "41388af1",
        "outputId": "e15b2112-960d-4725-843f-df1e6efa4976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "183434f6",
      "metadata": {
        "height": 31,
        "tags": [],
        "id": "183434f6",
        "outputId": "1265fb78-04a6-40bf-82a1-7e3453b978d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Langchain\\nTester\\n123\\nTesting\\nLane\\nTest\\nCity,\\nTS\\n56789\\ntestertester@email.com\\n(123)\\n456-7890\\nObjective:\\nHighly\\nskilled\\nand\\ndetail-oriented\\nLangchain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "docs[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1edb21d8",
      "metadata": {
        "id": "1edb21d8"
      },
      "source": [
        "# Saving the vector database for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea657123",
      "metadata": {
        "height": 31,
        "tags": [],
        "id": "ea657123"
      },
      "outputs": [],
      "source": [
        "vectordb.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0689733d"
      },
      "source": [
        "# Retrieval\n",
        "\n",
        "# Retrieving the vector database from the saved location"
      ],
      "id": "0689733d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "a0189dc5"
      },
      "outputs": [],
      "source": [
        "\n",
        "vectordbretrieve = Chroma(\n",
        "    persist_directory=persist_directory,\n",
        "    embedding_function=embedding\n",
        ")"
      ],
      "id": "a0189dc5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "3659e0f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467b0dc7-007d-44e2-e51b-9933d19909ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ],
      "source": [
        "print(vectordbretrieve._collection.count())"
      ],
      "id": "3659e0f7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q&A CHAT  USING Flan T5 model\n"
      ],
      "metadata": {
        "id": "liAMGpAdN9lw"
      },
      "id": "liAMGpAdN9lw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ed7feed"
      },
      "source": [
        "# Question Answering"
      ],
      "id": "4ed7feed"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Answering using the open-source google/flan-t5-small model\n"
      ],
      "metadata": {
        "id": "mDNcrxEyOzzS"
      },
      "id": "mDNcrxEyOzzS"
    },
    {
      "cell_type": "code",
      "source": [
        "HUGGINGFACEHUB_API_TOKEN=\"your-hugging-face-api-token\"\n",
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
        "# from langchain.llms import HuggingFaceHub\n",
        "repo_id = \"google/flan-t5-small\"\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=repo_id, model_kwargs={\"temperature\":0, \"max_length\": 64}\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoUFlIJSgCP5",
        "outputId": "10a515ae-9fa2-4f23-bbe8-e0e7e8420ef2"
      },
      "id": "WoUFlIJSgCP5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a689f25",
        "outputId": "25811bcf-8938-4741-bc33-1b9e1d443802"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Asking a question and performing similarity search\n",
        "question = \"What month and year did LangChain Tester graduate?\"\n",
        "docs = vectordbretrieve.similarity_search(question,k=3)\n",
        "len(docs)"
      ],
      "id": "3a689f25"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37ba2ad8"
      },
      "source": [
        "### RetrievalQA chain"
      ],
      "id": "37ba2ad8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 81,
        "id": "41f0003f"
      },
      "outputs": [],
      "source": [
        "# Retrieving answers using the Flan T5 model\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectordbretrieve.as_retriever()\n",
        ")"
      ],
      "id": "41f0003f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "aac0334e"
      },
      "outputs": [],
      "source": [
        "result = qa_chain({\"query\": question})"
      ],
      "id": "aac0334e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "10227125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76e05c32-7b74-4904-cd00-178d308a749f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'May 2022'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "result[\"result\"]"
      ],
      "id": "10227125"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fae8e55"
      },
      "source": [
        "### RetrievalQA chain with Prompt Template and return_source_documents"
      ],
      "id": "5fae8e55"
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a prompt template for question answering\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "owoOn8qN2p4O"
      },
      "id": "owoOn8qN2p4O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 132,
        "id": "fcb5817c"
      },
      "outputs": [],
      "source": [
        "# Running the question answering chain with the prompt template\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectordbretrieve.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")"
      ],
      "id": "fcb5817c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "e0fd6824"
      },
      "outputs": [],
      "source": [
        "# Asking a question and retrieving answers along with source documents\n",
        "question = \"What is LangChain Tester's email address?\""
      ],
      "id": "e0fd6824"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "f3a21b52"
      },
      "outputs": [],
      "source": [
        "result = qa_chain({\"query\": question})"
      ],
      "id": "f3a21b52"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "74e2f6cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e38c7984-4adb-434b-e904-faf2d197d3e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'123 Testing Lane Test City, TS 56789 testertester@email.com'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "result[\"result\"]"
      ],
      "id": "74e2f6cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "4a2531ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b098ae1-40bd-4f62-f2cb-ef1709039231"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Langchain\\nTester\\n123\\nTesting\\nLane\\nTest\\nCity,\\nTS\\n56789\\ntestertester@email.com\\n(123)\\n456-7890\\nObjective:\\nHighly\\nskilled\\nand\\ndetail-oriented\\nLangchain', metadata={'page': 0, 'source': './Langchain-Tester-Resume.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "result[\"source_documents\"][0]"
      ],
      "id": "4a2531ba"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}